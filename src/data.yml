machines:
  - name: Apple Macbook Air M2
    specs: |
      CPU: Apple M2
      RAM: LPDDR5 16GB
      Compiler: Homebrew Clang 17.0.6
      Kernel: Darwin Kernel Version 22.2.0: Fri Nov 11 02:06:26 PST 2022; root:xnu-8792.61.2~4/RELEASE_ARM64_T8112
      ... more to come

questions:
  - title: Memory vs Compute
    topic: Memory
    code1: |
      struct Foo {
        int values[30];
        int cached_bar{0};

        int bar() {
          if (cached_bar == 0) {
            for (int i = 0; i < 30; ++i) {
              cached_bar += values[i] * i;
            }
          }

          return cached_bar;
        }
      };

      std::vector<Foo> arr(1'000'000);

      for (auto &foo : arr) {
        Use(foo.bar());
      }
    code2: |
      struct Foo {
        int values[30];

        int bar() {
          int res{0};
          for (int i = 0; i < 30; ++i) {
            res += values[i] * i;
          }
          return res;
        }
      };

      std::vector<Foo> arr(1'000'000);

      for (auto &foo : arr) {
        Use(foo.bar());
      }
    answer: 2
    faster_factor: 3
    code_url: https://github.com/hgminh95/fast/blob/main/bench/memory/vs_memory.cpp
    machine: Apple Macbook Air M2
    explain: |
      TODO: say that memory is more common to be the issue

      In this example, the actual factor that cause majority of slow down is due to the
      write instruction. TODO go to next example.

      References:

      - TODO: find something
  - title: TLB Miss
    wip: true
    topic: Memory
    code1: |
      #include cpp
      int main() {
      }
    code2: |
      #include cpp
      int main() {
      }
    answer: 1
    faster_factor: 2
    machine: Apple Macbook Air M2
    explain: |
      References:

      - [Translation Lookaside Buffer](https://en.wikipedia.org/wiki/Translation_lookaside_buffer)
  - title: Zero Initialized Array
    topic: Memory
    code1: |
      std::vector<int> arr;
      arr.resize(100'000'000);
      std::fill(arr.begin(), arr.end(), 0);

      # Only measure this part
      for (auto i = 0u; i < arr.size(); ++i) {
        arr[i] = i;
      }
    code2: |
      std::vector<int> arr;
      arr.resize(100'000'000);

      # Only measure this part
      for (auto i = 0u; i < arr.size(); ++i) {
        arr[i] = i;
      }
    answer: 1
    faster_factor: 1.15
    code_url: https://github.com/hgminh95/fast/blob/main/bench/memory/page.cpp
    machine: Apple Macbook Air M2
    explain: |
      First time you access a page, it will trigger a minor page fault, that could be
      a bit slower. Zero-initialize the memory region will trigger the minor page
      fault, to make subsequent access faster.

      Beside `std::fill`, you can use `bzero` or `explicit_bzero`.

      References:

      - [Minor Page Fault](https://en.wikipedia.org/wiki/Page_fault#Minor)
  - title: Cache vs Memory
    topic: Memory
    code1: |
      constexpr int STRIDE = 1;

      for (auto i = 0u; i < arr.size(); ++i) {
        arr[i] = (i + STRIDE) % arr.size();
      }

      # Measure below part only
      int sum{0};
      int p{0};
      for (auto i = 0u; i < arr.size(); ++i) {
        sum += arr[p];
        p = arr[p];
      }
    code2: |
      constexpr int STRIDE = 4096;

      for (auto i = 0u; i < arr.size(); ++i) {
        arr[i] = (i + STRIDE) % arr.size();
      }

      # Measure below part only
      int sum{0};
      int p{0};
      for (auto i = 0u; i < arr.size(); ++i) {
        sum += arr[p];
        p = arr[p];
      }
    answer: 1
    faster_factor: 14.7
    code_url: https://github.com/hgminh95/fast/blob/main/bench/memory/cache.cpp
    machine: Apple Macbook Air M2
    explain: |
      There are actually a lot of stuff happening here, but the main gist is most of data
      access in the first code is done in cache, while most in 2nd thread have to go to
      memory (cache miss).

      You can use `perf` to see cache miss counter.

      - TODO: perf example here

      References:
      
      - [Measuring Cache Latencies - StackOverflow](https://stackoverflow.com/questions/21369381/measuring-cache-latencies)
  - title: Prefetch
    topic: Memory
    code1: |
      constexpr int STRIDE = 4096;

      for (auto i = 0u; i < arr.size(); ++i) {
        arr[i] = (i + STRIDE) % arr.size();
      }

      # Measure below part only
      int sum{0};
      int p{0};
      for (auto i = 0u; i < arr.size(); ++i) {
        __builtin_prefetch(&arr[(p + 1 * STRIDE) % arr.size()], 0, 0);
        __builtin_prefetch(&arr[(p + 2 * STRIDE) % arr.size()], 0, 0);

        sum += arr[p];
        p = arr[p];
      }
    code2: |
      constexpr int STRIDE = 4096;

      for (auto i = 0u; i < arr.size(); ++i) {
        arr[i] = (i + STRIDE) % arr.size();
      }

      # Measure below part only
      int sum{0};
      int p{0};
      for (auto i = 0u; i < arr.size(); ++i) {
        sum += arr[p];
        p = arr[p];
      }
    answer: 1
    faster_factor: 1.25
    explain: |
      If you know the memory address that you are going to access, or are likely be
      accessed, you can instruct CPU to prefetch them. That would help to reduce the
      wait if memory access is needed.

      Note that CPU also has a prefetcher, so don't try to do its work, only do this
      if you think the prefetcher cannot predict the next address.

      References:

      - [Cache Prefetching](https://en.wikipedia.org/wiki/Cache_prefetching)
  - title: False Sharing
    topic: Memory
    code1: |
      struct Foo {
        int x;
        int y;
        int z;
      };
      std::vector<Foo> arr(100'000);

      # Run in 2 threads
      for (int i = thread_idx; i < arr.size(); i += 2) {
        arr[i].x = i;
        arr[i].y = arr.size() - i;
        arr[i].z = arr.size() + i;
      }
    code2: |
      struct alignas(64) Foo {
        int x;
        int y;
        int z;
      };
      std::vector<Foo> arr(100'000);

      # Run in 2 threads
      for (int i = thread_idx; i < arr.size(); i += 2) {
        arr[i].x = i;
        arr[i].y = arr.size() - i;
        arr[i].z = arr.size() + i;
      }
    answer: 2
    faster_factor: 1.2
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/memory/false_sharing.cpp
    explain: |
      False sharing happens when 2 cores read/write to different variables in the same cache line. In the example,
      Foo struct only has 3 integers, which is smaller than 1 cache line (64 bytes). Therefore, multiple instances of Foo will
      fit into a single cache line, causing the possibility for 2 cores to read/write at the same cache line.

      Adding alignment for Foo struct so that 1 cache line only has 1 Foo instance (at the cost of more 
      and make the program run faster. Alternatively, you can divide the work between 2 threads differently (e.g. 0-size/2 to
      1 thread, and the rest to another thread).

      To measure effect of false sharing, you can use [perf c2c](https://man7.org/linux/man-pages/man1/perf-c2c.1.html).

      References:

        - [Wiki](https://en.wikipedia.org/wiki/False_sharing)
        - [docs.kernel.org](https://docs.kernel.org/kernel-hacking/false-sharing.html)
  - title: True Sharing
    topic: Memory
    wip: true
    code1: |
      constexpr int N = 128;
    code2: |
      constexpr int N = 128;
    answer: 2
    faster_factor: 3.4
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/memory/cache.cpp
    explain: |
      References:

        - [Wiki](https://en.wikipedia.org/wiki/Cache_placement_policies)
  - title: Cache Associativity
    topic: Memory
    wip: true
    code1: |
      constexpr int N = 64;

      for (auto j = 0u; j < 1024 / N; ++j) {
        for (auto i = 0u; i < N; ++i) {
          sum += arr1[i] + arr2[i];
        }
      }
    code2: |
      constexpr int N = 128;

      for (auto j = 0u; j < 1024 / N; ++j) {
        for (auto i = 0u; i < N; ++i) {
          sum += arr1[i] + arr2[i];
        }
      }
    answer: 2
    faster_factor: 3.4
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/memory/cache.cpp
    explain: |
      References:

        - [Wiki](https://en.wikipedia.org/wiki/Cache_placement_policies)
  - title: Cache Bank Conflict
    topic: Memory
    wip: true
    code1: |
      constexpr int N = 1;

      for (auto j = 0u; j < 1024 / N; ++j) {
        for (auto i = 0u; i < N; ++i) {
          sum += arr1[i] + arr2[i];
        }
      }
    code2: |
      constexpr int N = 2;

      for (auto j = 0u; j < 1024 / N; ++j) {
        for (auto i = 0u; i < N; ++i) {
          sum += arr1[i] + arr2[i];
        }
      }
    answer: 1
    faster_factor: 33.7
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/memory/cache.cpp
    explain: |
      TODO
  - title: Memory Bank Conflict
    topic: Memory
    wip: true
    code1: |
      constexpr int N = 1;
    code2: |
      constexpr int N = 2;
    answer: 1
    faster_factor: 33.7
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/memory/cache.cpp
    explain: |
      TODO
  - title: TLB Shoot Down
    topic: Memory
    wip: true
    code1: |
      for (int i = 0; i < 10'000'000; ++i) {
        sum += a[i % 1'000'000];
      }
    code2: |
      # Thread 1
      for (int i = 0; i < 1'000'000; ++i) {
        sum += a[i % 1'000'000];
      }

      # Thread 2
      while (++cnt) {
        if (cnt % 2 == 0)
          x = new int[10000];
        else
          delete [] x;
      }
    answer: 1
    faster_factor: 2
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/memory/tlb_shootdown.cpp
    explain: |
      TODO
  - title: Paused
    topic: Memory
    wip: true
    code1: |
      a
    code2: |
      b
    answer: 1
    faster_factor: 2
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/memory/tlb_shootdown.cpp
    explain: |
      TODO
  - title: Misalign
    wip: true
    topic: Memory
    code1: |
      a
    code2: |
      b
    answer: 1
    faster_factor: 2
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/memory/tlb_shootdown.cpp
    explain: |
      TODO
  - title: Recharge
    wip: true
    topic: Memory
    code1: |
      a
    code2: |
      b
    answer: 1
    faster_factor: 2
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/memory/tlb_shootdown.cpp
    explain: |
      TODO
  - title: Mooore Write
    wip: true
    topic: Memory
    code1: |
      a
    code2: |
      b
    answer: 1
    faster_factor: 2
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/memory/write.cpp
    explain: |
      TODO
  - title: Non Temporal Write
    wip: true
    topic: Memory
    code1: |
      a
    code2: |
      b
    answer: 1
    faster_factor: 2
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/memory/write.cpp
    explain: |
      TODO

  - title: Sorted Array
    topic: CPU
    code1: |
      std::vector<int> arr(100'000);
      # then fill with random value in [0, 256]

      for (auto i = 0u; i < 100'000; ++i) {
        if (arr[i] >= 128)
          sum += arr[i];
      }
    code2: |
      std::vector<int> arr(100'000);
      # then fill with random value in [0, 256]

      # do not benchmark this sort function
      std::sort(arr.begin(), arr.end())

      for (auto i = 0u; i < 100'000; ++i) {
        if (arr[i] >= 128)
          sum += arr[i];
      }
    answer: 2
    faster_factor: 9.6
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/sorted_array.cpp
    explain: |
      With sorted array, the condition `arr[i] >= 128` become easy to predicted (always false at the beginning, and then
      become always true). Without sorted array, that is harder to predict.

      CPU can run multiple instructions at the same time, but branch prevents it from happenning. Therefore, CPU try to
      predict result of the branch and execute instructions based on that prediction to keep the utilization high.

      References:

        - [Wiki](https://en.wikipedia.org/wiki/Branch_predictor)
        - [Why is processing a sorted array faster than processing an unsorted array?](https://stackoverflow.com/questions/11227809/why-is-processing-a-sorted-array-faster-than-processing-an-unsorted-array)
  - title: Modulo
    topic: CPU
    code1: |
      std::array<int, 5> modulos{11, 107, 1013, 19211, 81727};

      for (auto i = 0u; i < arr.size(); ++i) {
        sum += arr[i] % modulos[i * 5 / arr.size()];
      }
    code2: |
      for (auto i = 0u; i < arr.size(); ++i) {
        switch (i * 5 / arr.size()) {
          case 0:
            sum += arr[i] % 11;
            break;
          case 1:
            sum += arr[i] % 107;
            break;
          case 2:
            sum += arr[i] % 1013;
            break;
          case 3:
            sum += arr[i] % 19211;
            break;
          case 4:
            sum += arr[i] % 81727;
            break;
        }
      }
    answer: 2
    faster_factor: 1.3
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/modulo.cpp
    explain: |
      Integer modulo (and division) operation in CPU is slow. But there is a trick to convert
      [division by a constant into multiplication](https://en.wikipedia.org/wiki/Division_algorithm#Division_by_a_constant).

      Beware of the branching penalty though. The above example works because the branch is easily predicted.

      In case where you don't know the divisor in compile time, but you know same value is gonna be used multiple times,
      you can use something like [libdivide](https://libdivide.com/)

      References:
      
      - [Division Algorithm - Wiki](https://en.wikipedia.org/wiki/Division_algorithm)
  - title: Power Of Two
    topic: CPU
    code1: |
      int foo(int x) {
        return x % 3; 
      }
    code2: |
      int foo(int x) {
        return x % 128; 
      }
    answer: 2
    faster_factor: 1.2
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/power_of_two.cpp
    explain: |
      Arithmetic operation with power of two can usually be converted into bit shift, or mask
      operation, which is quite cheap

      - x * 2^n == x << n
      - x % 2^n == x & (1 << n - 1)

  - title: Dependency
    topic: CPU
    code1: |
      for (auto i = 0u; i < 90; ++i) {
        sum *= 10;
        sum += a[i];
      }
    code2: |
      for (auto i = 0u; i < 90; i += 3) {
        sum *= 1000;
        sum += a[i] * 100;
        sum += a[i + 1] * 10;
        sum += a[i + 2];
      }
    answer: 2
    faster_factor: 1.3
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/dependency.cpp
    explain: |
      The first code has to be run sequentially pretty much, since the add operation
      must be done after * 10 operation. While in the 2nd code, there are 3 add
      operation that can be done in any order, thus enable more parallelism in CPU.

      References:

      - [Superscalar Processor - Wiki](https://en.wikipedia.org/wiki/Superscalar_processor)
  - title: False Dependency
    topic: CPU
    wip: true
    code1: |
      #include
    code2: |
      #include
    answer: 2
    faster_factor: 2
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/sorted_array.cpp
    explain: |
      TODO
  - title: No Branch
    topic: CPU
    code1: |
      for (auto i = 0u; i < arr.size(); ++i) {
        if (arr[i] > 128)
          sum += arr[i];
      }
    code2: |
      for (auto i = 0u; i < arr.size(); ++i) {
        sum += arr[i] * (arr[i] > 128);
      }
    answer: 2
    faster_factor: 9
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/sorted_array.cpp
    explain: |
      Eventhough there are a lot more instructions in the 2nd example, eliminating
      branch make it faster due to higher of parallelism achieved on the CPU.

      Part of a reason that compiler does not optimize the first example is because
      it is not obvious the branchless edition is faster. As you see in `Sorted Array`,
      branch one, with a clean pattern, will outperform the branchless one, due to extra
      computation it needs.

      References:

      - [Branchless Programming - Algorithmica](https://en.algorithmica.org/hpc/pipelining/branchless/)
  - title: No Branch 2
    topic: CPU
    code1: |
      for (auto i = 0u; i < arr.size(); ++i) {
        if (arr[i] > 128)
          sum += arr[i];
      }
    code2: |
      int sum[2] = {0, 0};
      for (auto i = 0u; i < arr.size(); ++i) {
        sum[arr[i] > 128] += arr[i];
      }
      // The answer is in sum[true]
    answer: 2
    faster_factor: 1.83
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/sorted_array.cpp
    explain: |
      Similar to [No Branch](/q/no_branch.html). This is a difference approach, which
      is more general. Instead of having branch, you store the compute result in both
      branch, and discard the incorrect one at the end.
  - title: Register Spill
    topic: CPU
    code1: |
      // arr.size == 1'000'000
      constexpr int N = 4;

      for (auto i = 0u; i < arr.size(); i += N) {
        for (int j = 0; j < N; ++j) {
          sum += arr[i + j] * (i + j);
        }
      }
    code2: |
      // arr.size == 1'000'000
      constexpr int N = 8;

      for (auto i = 0u; i < arr.size(); i += N) {
        for (int j = 0; j < N; ++j) {
          sum += arr[i + j] * (i + j);
        }
      }
    answer: 1
    faster_factor: 3.7
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/register.cpp
    explain: |
      There are limited amount of registers in CPU. So if the calculation is large amount
      (in the sense that you need to have a lot intermediate values stored, some will have
      to go to CPU cache.

      In these 2 examples, the inner loops will be unrolled, as N is small enough. And with
      larger N, the amount of intermediate values for these calculation grow, leading to
      downgrade performance.

      References:
      
      - [Register Allocation - Wiki](https://en.wikipedia.org/wiki/Register_allocation)
      - [Register Renaming - Wiki](https://en.wikipedia.org/wiki/Register_renaming)
  - title: Pointer Chasing
    topic: CPU
    wip: true
    code1: |
      #include
    code2: |
      #include
    answer: 2
    faster_factor: 2
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/sorted_array.cpp
    explain: |
      TODO
  - title: Store-To-Loading Forwarding
    topic: CPU
    wip: true
    code1: |
      #include
    code2: |
      #include
    answer: 2
    faster_factor: 2
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/sorted_array.cpp
    explain: |
      TODO
  - title: Async
    topic: CPU
    wip: true
    code1: |
      #include
    code2: |
      #include
    answer: 2
    faster_factor: 2
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/sorted_array.cpp
    explain: |
      TODO



  - title: Inline vs Function Call
    topic: C++
    wip: true
    code1: |
      __attribute__(always_inline) int foo(int x, int y) {
        return x + y;
      }
    code2: |
      __attribute__(noinline) int foo(int x, int y) {
        return x + y;
      }
    answer: 1
    faster_factor: "?"
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpp/function_call.cpp
    explain: |
      Inline function is always faster.

      TODO

  - title: Function Call vs Virtual Function Call
    topic: C++
    wip: true
    code1: |
      #include
    code2: |
      #include
    answer: 2
    faster_factor: "?"
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpp/function_call.cpp
    explain: |
      TODO

  - title: Different Type of Static Variable
    topic: C++
    code1: |
      struct Foo {
        int Add(int x) {
          static Bar a;
          return a += x;
        }
      };
    code2: |
      struct Foo {
        static inline int a{0};

        int Add(int x) {
          return a += x;
        }
      };
    answer: 2
    faster_factor: "?"
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/static_variable.cpp
    explain: |
      TODO

  - title: Signed vs Unsigned
    topic: C++
    wip: true
    code1: |
      struct Foo {
    code2: |
      struct Foo {
    answer: 2
    faster_factor: "?"
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/static_variable.cpp
    explain: |
      TODO

  - title: Shared Pointer
    topic: C++
    wip: true
    code1: |
      struct Foo {
    code2: |
      struct Foo {
    answer: 2
    faster_factor: "?"
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/static_variable.cpp
    explain: |
      TODO

  - title: Small
    topic: C++
    code1: |
      for (int j = 0; j < 23; ++j) {
        std::string s;
        for (auto i = 0u; i < 22; ++i)
          s += 'a';
      }
    code2: |
      for (int j = 0; j < 22; ++j) {
        std::string s;
        for (auto i = 0u; i < 23; ++i)
          s += 'a';
      }
    answer: 1
    faster_factor: 2
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpp/string.cpp
    explain: |
      Small String Optimization (SSO) is a way to avoid heap allocation by reusing the
      space for metadata (e.g. pointer, capacity, size) in case the length of the
      string is small.

      For Clang, the small string size is capped at 22 bytes (at the time of writing)

      References:

      - [An informal comparison of the three major implementations of std::string](https://devblogs.microsoft.com/oldnewthing/20240510-00/?p=109742)
  - title: Chaining Function
    topic: C++
    wip: true
    code1: |
      struct Foo {
    code2: |
      struct Foo {
    answer: 2
    faster_factor: "?"
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/static_variable.cpp
    explain: |
      TODO

  - title: ABI
    topic: C++
    wip: true
    code1: |
      struct Foo {
    code2: |
      struct Foo {
    answer: 2
    faster_factor: "?"
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/static_variable.cpp
    explain: |
      TODO

  - title: Batch Processing
    topic: C++
    wip: true
    code1: |
      struct Foo {
    code2: |
      struct Foo {
    answer: 2
    faster_factor: "?"
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/static_variable.cpp
    explain: |
      TODO

  - title: sqrt
    topic: C++
    wip: true
    code1: |
      std::sqrt(3);
    code2: |
      std::sqrt(4);
    answer: 2
    faster_factor: "?"
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpp/math.cpp
    explain: |
      TODO

  - title: Loop Reordering
    topic: C++
    wip: true
    code1: |
      struct Foo {
    code2: |
      struct Foo {
    answer: 2
    faster_factor: "?"
    machine: Apple Macbook Air M2
    code_url: https://github.com/hgminh95/fast/blob/main/bench/cpu/static_variable.cpp
    explain: |
      TODO

  - title: Moving Data
    topic: GPU
    wip: true
    code1: |
      #include cpp
      int main() {
      }
    code2: |
      #include cpp
      int main() {
      }
    answer: 1
    faster_factor: 2
    explain: |
      TODO
  - title: Coalesced Access
    topic: GPU
    wip: true
    code1: |
      #include cpp
      int main() {
      }
    code2: |
      #include cpp
      int main() {
      }
    answer: 1
    faster_factor: 2
    explain: |
      TODO
  - title: Misaligned Access
    topic: GPU
    wip: true
    code1: |
      #include cpp
      int main() {
      }
    code2: |
      #include cpp
      int main() {
      }
    answer: 1
    faster_factor: 2
    explain: |
      TODO
  - title: The Swizzle Operator
    topic: GPU
    wip: true
    code1: |
      #include cpp
      int main() {
      }
    code2: |
      #include cpp
      int main() {
      }
    answer: 1
    faster_factor: 2
    explain: |
      TODO
  - title: Kernel Fusion
    topic: GPU
    wip: true
    code1: |
      #include cpp
      int main() {
      }
    code2: |
      #include cpp
      int main() {
      }
    answer: 1
    faster_factor: 2
    explain: |
      TODO
  - title: Kernel Fission
    topic: GPU
    wip: true
    code1: |
      #include cpp
      int main() {
      }
    code2: |
      #include cpp
      int main() {
      }
    answer: 1
    faster_factor: 2
    explain: |
      TODO

  - title: Pipelining
    topic: RTL
    wip: true
    code1: |
      #include cpp
      int main() {
      }
    code2: |
      #include cpp
      int main() {
      }
    answer: 1
    faster_factor: 2
    explain: |
      TODO
  - title: Removing Pipeline Register
    topic: RTL
    wip: true
    code1: |
      #include cpp
      int main() {
      }
    code2: |
      #include cpp
      int main() {
      }
    answer: 1
    faster_factor: 2
    explain: |
      TODO
  - title: Register Layers
    topic: RTL
    wip: true
    code1: |
      #include cpp
      int main() {
      }
    code2: |
      #include cpp
      int main() {
      }
    answer: 1
    faster_factor: 2
    explain: |
      TODO
  - title: Register Balancing
    topic: RTL
    wip: true
    code1: |
      #include cpp
      int main() {
      }
    code2: |
      #include cpp
      int main() {
      }
    answer: 1
    faster_factor: 2
    explain: |
      TODO
  - title: Control-based Logic Reuse
    topic: RTL
    wip: true
    code1: |
      #include cpp
      int main() {
      }
    code2: |
      #include cpp
      int main() {
      }
    answer: 1
    faster_factor: 2
    explain: |
      TODO
  - title: Priority Encoders
    topic: RTL
    wip: true
    code1: |
      #include cpp
      int main() {
      }
    code2: |
      #include cpp
      int main() {
      }
    answer: 1
    faster_factor: 2
    explain: |
